<!doctype html>

<head>
  <meta charset="utf8">
  <script src="../dist/template.v2.js"></script>

  <d-front-matter>
    <script type="text/yml">
      title: Demo Title Attention and Augmented Recurrent Neural Networks
      published: Jan 10, 2017
      authors:
      - Chris Olah: http://shancarter.com
      - Shan Carter: http://shancarter.com
      affiliations:
      - Google Brain
      - Google Brain: http://g.co/brain
    </script>
  </d-front-matter>
</head>

<body>
<d-article>
  <d-title>
    <h1>How to Use t-SNE Effectively</h1>
    <h2>Although extremely useful for visualizing high-dimensional data, t-SNE plots can sometimes be mysterious or misleading.</h2>
    <d-byline></d-byline>
  </d-title>
  <!-- <d-abstract>
    <p>This is the first paragraph of the article. Test a long&thinsp;&mdash;&thinsp;dash -- here it is.</p>
  </d-abstract> -->
  <p>A popular method for exploring high-dimensional data is something called t-SNE, introduced by van der Maaten and Hinton in 2008 [1]. The technique has become widespread in the field of machine learning, since it has an almost magical ability to create compelling two-dimensonal “maps” from data with hundreds or even thousands of dimensions. Although impressive, these images can be tempting to misread. The purpose of this note is to prevent some common misreadings.
  <p>Before diving in: if you haven’t encountered t-SNE before, here’s what you need to know about the math behind it. The goal is to take a set of points in a high-dimensional space and find a faithful representation of those points in a lower-dimensional space, typically the 2D plane. The algorithm is non-linear and adapts to the underlying data, performing different transformations on different regions. Those differences can be a major source of confusion.
  <p>This is the first paragraph of the article. Test a long&thinsp;&mdash;&thinsp;dash -- here it is.</p>
  <p>Test for owner's possessive. Test for "quoting a passage." And another sentence. Or two. Some flopping fins; for diving.</p>
  <p>Here's a test of an inline equation <d-math>c = a^2 + b^2</d-math>. And then there's a block equation:</p>
  <d-math block>
      c = \pm \sqrt{ \sum_{i=0}^{n}{a^{222} + b^2}}
  </d-math>
  <p>
    Math can also be quite involved:
    <d-math block>
      f(x) = \int_{-\infty}^\infty\hat f(\xi)\,e^{2 \pi i \xi x}\,d\xi
    </d-math>
    <d-math block>
      \frac{1}{\Bigl(\sqrt{\phi \sqrt{5}}-\phi\Bigr) e^{\frac25 \pi}} = 1+\frac{e^{-2\pi}} {1+\frac{e^{-4\pi}} {1+\frac{e^{-6\pi}} {1+\frac{e^{-8\pi}} {1+\cdots} } } }
    </d-math>
  </p>
  <p>We can<d-cite key="mercier2011humans"></d-cite> also cite <d-cite key="gregor2015draw,mercier2011humans"></d-cite> external publications. <d-cite key="dong2014image,dumoulin2016guide,mordvintsev2015inceptionism"></d-cite></p>
  <p>We should also be testing footnotes<d-footnote>This will become a hoverable footnote. This will become a hoverable footnote. This will become a hoverable footnote. This will become a hoverable footnote. This will become a hoverable footnote. This will become a hoverable footnote. This will become a hoverable footnote. This will become a hoverable footnote.</d-footnote>. There are multiple footnotes, and they appear in the appendix<d-footnote>Given I have coded them right. Also, here's math in a footnote: <d-math>c = \sum_0^i{x}</d-math>. Also, a citation. Box-ception<d-cite key='gregor2015draw'></d-cite>!</d-footnote> as well.</p>
  <table>
    <thead>
      <tr><th>First</th><th>Second</th><th>Third</th></tr>
    </thead>
    <tbody>
      <tr><td>23</td><td>654</td><td>23</td></tr>
      <tr><td>14</td><td>54</td><td>34</td></tr>
      <tr><td>234</td><td>54</td><td>23</td></tr>
    </tbody>
  </table>
  <h2>Displaying code snippets</h2>
  <p>Some inline javascript:<d-code language="javascript">var x = 25;</d-code></p>
  <p>Here's a javascript code block.</p>
  <d-code block language="javascript">
      var x = 25;
      function(x){
        return x * x;
      }
  </d-code>
  <p>We also support python.</p>
  <d-code block language="python">
    # Python 3: Fibonacci series up to n
    def fib(n):
      a, b = 0, 1
        while a < n:
          print(a, end=' ')
          a, b = b, a+b
  </d-code>
  <d-figure id="last-figure"></d-figure>
  <script>
    const figure = document.querySelector("d-figure#last-figure");
    const initTag = document.createElement("span");
    initTag.textContent = "initialized!"
    figure.appendChild(initTag);
    figure.addEventListener("ready", function() {
      const initTag = figure.querySelector("span");
      initTag.textContent = "ready"
      console.log('ready')
    });
    figure.addEventListener("onscreen", function() {
      const initTag = figure.querySelector("span");
      initTag.textContent = "onscreen"
      console.log('onscreen')
    });
    figure.addEventListener("offscreen", function() {
      const initTag = figure.querySelector("span");
      initTag.textContent = "offscreen!"
      console.log('offscreen')
    });
  </script>
  <p>That's it for the example article!</p>
  <aside>Some text.</aside>
</d-article>

<d-appendix>
  <d-acknowledgements>
    <h3>Contributions</h3>
    <p>Some text describing who did what.</p>
    <h3>Reviewers</h3>
    <p>Some text with links describing who reviewed the article.</p>
  </d-acknowledgements>

  <d-footnote-list></d-footnote-list>

  <d-bibliography><script type="text/bibtex">

      @article{gregor2015draw,
        title={DRAW: A recurrent neural network for image generation},
        author={Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
        journal={arXiv preprint arXiv:1502.04623},
        year={2015},
        url ={https://arxiv.org/pdf/1502.04623.pdf}
      }
      @article{mercier2011humans,
        title={Why do humans reason? Arguments for an argumentative theory},
        author={Mercier, Hugo and Sperber, Dan},
        journal={Behavioral and brain sciences},
        volume={34},
        number={02},
        pages={57--74},
        year={2011},
        publisher={Cambridge Univ Press},
        doi={10.1017/S0140525X10000968}
      }

      @article{dong2014image,
        title={Image super-resolution using deep convolutional networks},
        author={Dong, Chao and Loy, Chen Change and He, Kaiming and Tang, Xiaoou},
        journal={arXiv preprint arXiv:1501.00092},
        year={2014},
        url={https://arxiv.org/pdf/1501.00092.pdf}
      }

      @article{dumoulin2016adversarially,
        title={Adversarially Learned Inference},
        author={Dumoulin, Vincent and Belghazi, Ishmael and Poole, Ben and Lamb, Alex and Arjovsky, Martin and Mastropietro, Olivier and Courville, Aaron},
        journal={arXiv preprint arXiv:1606.00704},
        year={2016},
        url={https://arxiv.org/pdf/1606.00704.pdf}
      }

      @article{dumoulin2016guide,
        title={A guide to convolution arithmetic for deep learning},
        author={Dumoulin, Vincent and Visin, Francesco},
        journal={arXiv preprint arXiv:1603.07285},
        year={2016},
        url={https://arxiv.org/pdf/1603.07285.pdf}
      }

      @article{gauthier2014conditional,
        title={Conditional generative adversarial nets for convolutional face generation},
        author={Gauthier, Jon},
        journal={Class Project for Stanford CS231N: Convolutional Neural Networks for Visual Recognition, Winter semester},
        volume={2014},
        year={2014},
        url={http://www.foldl.me/uploads/papers/tr-cgans.pdf}
      }

      @article{johnson2016perceptual,
        title={Perceptual losses for real-time style transfer and super-resolution},
        author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
        journal={arXiv preprint arXiv:1603.08155},
        year={2016},
        url={https://arxiv.org/pdf/1603.08155.pdf}
      }

      @article{mordvintsev2015inceptionism,
        title={Inceptionism: Going deeper into neural networks},
        author={Mordvintsev, Alexander and Olah, Christopher and Tyka, Mike},
        journal={Google Research Blog},
        year={2015},
        url={https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html}
      }

      @misc{mordvintsev2016deepdreaming,
        title={DeepDreaming with TensorFlow},
        author={Mordvintsev, Alexander},
        year={2016},
        url={https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb},
      }

      @article{radford2015unsupervised,
        title={Unsupervised representation learning with deep convolutional generative adversarial networks},
        author={Radford, Alec and Metz, Luke and Chintala, Soumith},
        journal={arXiv preprint arXiv:1511.06434},
        year={2015},
        url={https://arxiv.org/pdf/1511.06434.pdf}
      }

      @inproceedings{salimans2016improved,
        title={Improved techniques for training gans},
        author={Salimans, Tim and Goodfellow, Ian and Zaremba, Wojciech and Cheung, Vicki and Radford, Alec and Chen, Xi},
        booktitle={Advances in Neural Information Processing Systems},
        pages={2226--2234},
        year={2016},
        url={https://arxiv.org/pdf/1606.03498.pdf}
      }

      @article{shi2016deconvolution,
        title={Is the deconvolution layer the same as a convolutional layer?},
        author={Shi, Wenzhe and Caballero, Jose and Theis, Lucas and Huszar, Ferenc and Aitken, Andrew and Ledig, Christian and Wang, Zehan},
        journal={arXiv preprint arXiv:1609.07009},
        year={2016},
        url={https://arxiv.org/pdf/1609.07009.pdf}
      }

    </script></d-bibliography>

  <distill-appendix> </distill-appendix>
</d-appendix>
</body>
